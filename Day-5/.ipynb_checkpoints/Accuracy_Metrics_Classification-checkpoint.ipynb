{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topics\n",
    "1. Review of model evaluation\n",
    "2. Model evaluation procedures\n",
    "3. Model evaluation metrics\n",
    "4. Classification accuracy\n",
    "5. Confusion matrix\n",
    "6. Metrics computed from a confusion matrix\n",
    "7. Receiver Operating Characteristic (ROC) Curves\n",
    "8. Area Under the Curve (AUC)\n",
    "9. Confusion Matrix Resources\n",
    "10. ROC and AUC Resources\n",
    "11. Other Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Review of model evaluation\n",
    "\n",
    "- Need a way to choose between models: different model types, tuning parameters, and features\n",
    "- Use a **model evaluation procedure** to estimate how well a model will generalize to out-of-sample data\n",
    "- Requires a **model evaluation metric** to quantify the model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Model evaluation procedures\n",
    "\n",
    "1. **Training and testing on the same data**\n",
    "    - Rewards overly complex models that \"overfit\" the training data and won't necessarily generalize\n",
    "    \n",
    "2. **Train/test split**\n",
    "    - Split the dataset into two pieces, so that the model can be trained and tested on different data\n",
    "    - Better estimate of out-of-sample performance, but still a \"high variance\" estimate\n",
    "    - Useful due to its speed, simplicity, and flexibility\n",
    "3. **K-fold cross-validation**\n",
    "    - Systematically create \"K\" train/test splits and average the results together\n",
    "    - Even better estimate of out-of-sample performance\n",
    "    - Runs \"K\" times slower than train/test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Model evaluation metrics\n",
    "\n",
    "- **Regression problems:** Mean Absolute Error, Mean Squared Error, Root Mean Squared Error\n",
    "- **Classification problems:** Classification accuracy\n",
    "    - There are many more metrics, and we will discuss them today"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Classification accuracy\n",
    "\n",
    "[Pima Indian Diabetes dataset](https://www.kaggle.com/uciml/pima-indians-diabetes-database/downloads/pima-indians-diabetes-database.zip/1) UCIML dataset in Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data into a Pandas DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "#url = 'https://www.kaggle.com/uciml/pima-indians-diabetes-database/downloads/pima-indians-diabetes-database.zip/1'\n",
    "\n",
    "col_names = ['pregnant', 'glucose', 'bp', 'skin', 'insulin', 'bmi', 'pedigree', 'age','label']\n",
    "\n",
    "#pima = pd.read_csv(url, header=None, names=col_names)\n",
    "\n",
    "pima = pd.read_csv('dataset/diabetes.csv')#, header=None, names=col_names)\n",
    "pima.columns=col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnant</th>\n",
       "      <th>glucose</th>\n",
       "      <th>bp</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnant  glucose  bp  skin  insulin   bmi  pedigree  age  label\n",
       "0         6      148  72    35        0  33.6     0.627   50      1\n",
       "1         1       85  66    29        0  26.6     0.351   31      0\n",
       "2         8      183  64     0        0  23.3     0.672   32      1\n",
       "3         1       89  66    23       94  28.1     0.167   21      0\n",
       "4         0      137  40    35      168  43.1     2.288   33      1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the first 5 rows of data from the dataframe\n",
    "pima.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- label\n",
    "    - 1: diabetes\n",
    "    - 0: no diabetes\n",
    "- pregnant\n",
    "    - number of times pregnant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Can we predict the diabetes status of a patient given their health measurements?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X and y\n",
    "feature_cols = ['pregnant', 'insulin', 'bmi', 'age']\n",
    "\n",
    "# X is a matrix, hence we use [] to access the features we want in feature_cols\n",
    "X = pima[feature_cols]\n",
    "\n",
    "# y is a vector, hence we use dot to access 'label'\n",
    "y = pima.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split X and y into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VIPUL.GAUR\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train a logistic regression model on the training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# instantiate model\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# fit model\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make class predictions for the testing set\n",
    "y_pred_class = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification accuracy:** percentage of correct predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6927083333333334\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy\n",
    "from sklearn import metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification accuracy is 69%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Null accuracy:** accuracy that could be achieved by always predicting the most frequent class\n",
    "- We must always compare with this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    130\n",
       "1     62\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the class distribution of the testing set (using a Pandas Series method)\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3229166666666667"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the percentage of ones\n",
    "# because y_test only contains ones and zeros, we can simply calculate the mean = percentage of ones\n",
    "y_test.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "32% of the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6770833333333333"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the percentage of zeros\n",
    "1 - y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6770833333333333"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate null accuracy in a single line of code\n",
    "# only for binary classification problems coded as 0/1\n",
    "max(y_test.mean(), 1 - y_test.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that a dumb model that always predicts 0 would be right 68% of the time\n",
    "- This shows how classification accuracy is not that good as it's close to a dumb model\n",
    "- It's a good way to know the minimum we should achieve with our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.677083\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate null accuracy (for multi-class classification problems)\n",
    "y_test.value_counts().head(1) / len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the **true** and **predicted** response values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: [1 0 0 1 0 0 1 1 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 0 0]\n",
      "False: [0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# print the first 25 true and predicted responses\n",
    "print('True:', y_test.values[0:25])\n",
    "print('False:', y_pred_class[0:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "- Classification accuracy is the **easiest classification metric to understand**\n",
    "- But, it does not tell you the **underlying distribution** of response values\n",
    "    - We examine by calculating the null accuracy\n",
    "- And, it does not tell you what **\"types\" of errors** your classifier is making"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Confusion matrix\n",
    "\n",
    "Table that describes the performance of a classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[118  12]\n",
      " [ 47  15]]\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT: first argument is true values, second argument is predicted values\n",
    "# this produces a 2x2 numpy array (matrix)\n",
    "print(metrics.confusion_matrix(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Small confusion matrix](img/09_confusion_matrix_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Every observation in the testing set is represented in **exactly one box**\n",
    "- It's a 2x2 matrix because there are **2 response classes**\n",
    "- The format shown here is **not** universal\n",
    "    - Take attention to the format when interpreting a confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basic terminology**\n",
    "\n",
    "- **True Positives (TP):** we *correctly* predicted that they *do* have diabetes\n",
    "    - 15\n",
    "- **True Negatives (TN):** we *correctly* predicted that they *don't* have diabetes\n",
    "    - 118\n",
    "- **False Positives (FP):** we *incorrectly* predicted that they *do* have diabetes (a \"Type I error\")\n",
    "    - 12\n",
    "    - Falsely predict positive\n",
    "    - Type I error\n",
    "- **False Negatives (FN):** we *incorrectly* predicted that they *don't* have diabetes (a \"Type II error\")\n",
    "    - 47\n",
    "    - Falsely predict negative\n",
    "    - Type II error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 0: negative class\n",
    "- 1: positive class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True [1 0 0 1 0 0 1 1 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 0 0]\n",
      "Pred [0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# print the first 25 true and predicted responses\n",
    "print('True', y_test.values[0:25])\n",
    "print('Pred', y_pred_class[0:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[118  12]\n",
      " [ 47  15]]\n"
     ]
    }
   ],
   "source": [
    "# save confusion matrix and slice into four pieces\n",
    "confusion = metrics.confusion_matrix(y_test, y_pred_class)\n",
    "print(confusion)\n",
    "#[row, column]\n",
    "TP = confusion[1, 1]\n",
    "TN = confusion[0, 0]\n",
    "FP = confusion[0, 1]\n",
    "FN = confusion[1, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Large confusion matrix](img/09_confusion_matrix_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Metrics computed from a confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification Accuracy:** Overall, how often is the classifier correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6927083333333334\n",
      "0.6927083333333334\n"
     ]
    }
   ],
   "source": [
    "# use float to perform true division, not integer division\n",
    "print((TP + TN) / float(TP + TN + FP + FN))\n",
    "print(metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification Error:** Overall, how often is the classifier incorrect?\n",
    "\n",
    "- Also known as \"Misclassification Rate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3072916666666667\n",
      "0.30729166666666663\n"
     ]
    }
   ],
   "source": [
    "classification_error = (FP + FN) / float(TP + TN + FP + FN)\n",
    "\n",
    "print(classification_error)\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sensitivity:** When the actual value is positive, how often is the prediction correct?\n",
    "- Something we want to maximize\n",
    "- How \"sensitive\" is the classifier to detecting positive instances?\n",
    "- Also known as \"True Positive Rate\" or \"Recall\"\n",
    "- TP / all positive\n",
    "    - all positive = TP + FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24193548387096775\n",
      "0.24193548387096775\n"
     ]
    }
   ],
   "source": [
    "sensitivity = TP / float(FN + TP)\n",
    "\n",
    "print(sensitivity)\n",
    "print(metrics.recall_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Specificity:** When the actual value is negative, how often is the prediction correct?\n",
    "- Something we want to maximize\n",
    "- How \"specific\" (or \"selective\") is the classifier in predicting positive instances?\n",
    "- TN / all negative \n",
    "    - all negative = TN + FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9076923076923077\n"
     ]
    }
   ],
   "source": [
    "specificity = TN / (TN + FP)\n",
    "\n",
    "print(specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our classifier\n",
    "- Highly specific\n",
    "- Not sensitive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**False Positive Rate:** When the actual value is negative, how often is the prediction incorrect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09230769230769231\n",
      "0.09230769230769231\n"
     ]
    }
   ],
   "source": [
    "false_positive_rate = FP / float(TN + FP)\n",
    "\n",
    "print(false_positive_rate)\n",
    "print(1 - specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Precision:** When a positive value is predicted, how often is the prediction correct?\n",
    "\n",
    "- How \"precise\" is the classifier when predicting positive instances?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5555555555555556\n",
      "0.5555555555555556\n"
     ]
    }
   ],
   "source": [
    "precision = TP / float(TP + FP)\n",
    "\n",
    "print(precision)\n",
    "print(metrics.precision_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many other metrics can be computed: F1 score, Matthews correlation coefficient, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "- Confusion matrix gives you a **more complete picture** of how your classifier is performing\n",
    "- Also allows you to compute various **classification metrics**, and these metrics can guide your model selection\n",
    "\n",
    "**Which metrics should you focus on?**\n",
    "\n",
    "- Choice of metric depends on your **business objective**\n",
    "    - Identify if FP or FN is more important to reduce\n",
    "    - Choose metric with relevant variable (FP or FN in the equation)\n",
    "- **Spam filter** (positive class is \"spam\"): \n",
    "    - Optimize for **precision or specificity** \n",
    "        - precision\n",
    "            - false positive as variable\n",
    "        - specificity\n",
    "            - false positive as variable\n",
    "    - Because false negatives (spam goes to the inbox) are more acceptable than false positives (non-spam is caught by the spam filter)\n",
    "- **Fraudulent transaction detector** (positive class is \"fraud\"): \n",
    "    - Optimize for **sensitivity**\n",
    "        - FN as a variable\n",
    "    - Because false positives (normal transactions that are flagged as possible fraud) are more acceptable than false negatives (fraudulent transactions that are not detected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Receiver Operating Characteristic (ROC) Curves \n",
    "\n",
    "**Question:** Wouldn't it be nice if we could see how sensitivity and specificity are affected by various thresholds, without actually changing the threshold?\n",
    "\n",
    "**Answer:** Plot the ROC curve.\n",
    "- Receiver Operating Characteristic (ROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# IMPORTANT: first argument is true values, second argument is predicted probabilities\n",
    "\n",
    "# we pass y_test and y_pred_prob\n",
    "# we do not use y_pred_class, because it will give incorrect results without generating an error\n",
    "# roc_curve returns 3 objects fpr, tpr, thresholds\n",
    "# fpr: false positive rate\n",
    "# tpr: true positive rate\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_prob)\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.title('ROC curve for diabetes classifier')\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ROC curve can help you to **choose a threshold** that balances sensitivity and specificity in a way that makes sense for your particular context\n",
    "- You can't actually **see the thresholds** used to generate the curve on the ROC curve itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that accepts a threshold and prints sensitivity and specificity\n",
    "def evaluate_threshold(threshold):\n",
    "    print('Sensitivity:', tpr[thresholds > threshold][-1])\n",
    "    print('Specificity:', 1 - fpr[thresholds > threshold][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity: 0.24193548387096775\n",
      "Specificity: 0.9076923076923077\n"
     ]
    }
   ],
   "source": [
    "evaluate_threshold(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity: 0.7258064516129032\n",
      "Specificity: 0.6153846153846154\n"
     ]
    }
   ],
   "source": [
    "evaluate_threshold(0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. AUC\n",
    "AUC is the **percentage** of the ROC plot that is **underneath the curve**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7245657568238213\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT: first argument is true values, second argument is predicted probabilities\n",
    "print(metrics.roc_auc_score(y_test, y_pred_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- AUC is useful as a **single number summary** of classifier performance\n",
    "- Higher value = better classifier\n",
    "- If you randomly chose one positive and one negative observation, AUC represents the likelihood that your classifier will assign a **higher predicted probability** to the positive observation\n",
    "- AUC is useful even when there is **high class imbalance** (unlike classification accuracy)\n",
    "    - Fraud case\n",
    "        - Null accuracy almost 99%\n",
    "        - AUC is useful here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VIPUL.GAUR\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\VIPUL.GAUR\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\VIPUL.GAUR\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\VIPUL.GAUR\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\VIPUL.GAUR\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\VIPUL.GAUR\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\VIPUL.GAUR\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\VIPUL.GAUR\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\VIPUL.GAUR\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\VIPUL.GAUR\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7378233618233618"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate cross-validated AUC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(logreg, X, y, cv=10, scoring='roc_auc').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use both of these whenever possible\n",
    "\n",
    "1. **Confusion matrix advantages:**\n",
    "\n",
    "    - Allows you to calculate a **variety of metrics**\n",
    "    - Useful for **multi-class problems** (more than two response classes)\n",
    "\n",
    "2. **ROC/AUC advantages:**\n",
    "\n",
    "    - Does not require you to **set a classification threshold**\n",
    "    - Still useful when there is **high class imbalance**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Confusion Matrix Resources\n",
    "\n",
    "- Blog post: [Simple guide to confusion matrix terminology](http://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/) by me\n",
    "- Videos: [Intuitive sensitivity and specificity](https://www.youtube.com/watch?v=U4_3fditnWg) (9 minutes) and [The tradeoff between sensitivity and specificity](https://www.youtube.com/watch?v=vtYDyGGeQyo) (13 minutes) by Rahul Patwari\n",
    "- Notebook: [How to calculate \"expected value\"](https://github.com/podopie/DAT18NYC/blob/master/classes/13-expected_value_cost_benefit_analysis.ipynb) from a confusion matrix by treating it as a cost-benefit matrix (by Ed Podojil)\n",
    "- Graphic: How [classification threshold](https://media.amazonwebservices.com/blog/2015/ml_adjust_model_1.png) affects different evaluation metrics (from a [blog post](https://aws.amazon.com/blogs/aws/amazon-machine-learning-make-data-driven-decisions-at-scale/) about Amazon Machine Learning)\n",
    "\n",
    "\n",
    "### 11. ROC and AUC Resources\n",
    "\n",
    "- Lesson notes: [ROC Curves](http://ebp.uga.edu/courses/Chapter%204%20-%20Diagnosis%20I/8%20-%20ROC%20curves.html) (from the University of Georgia)\n",
    "- Video: [ROC Curves and Area Under the Curve](https://www.youtube.com/watch?v=OAl6eAyP-yo) (14 minutes) by me, including [transcript and screenshots](http://www.dataschool.io/roc-curves-and-auc-explained/) and a [visualization](http://www.navan.name/roc/)\n",
    "- Video: [ROC Curves](https://www.youtube.com/watch?v=21Igj5Pr6u4) (12 minutes) by Rahul Patwari\n",
    "- Paper: [An introduction to ROC analysis](http://people.inf.elte.hu/kiss/13dwhdm/roc.pdf) by Tom Fawcett\n",
    "- Usage examples: [Comparing different feature sets](http://research.microsoft.com/pubs/205472/aisec10-leontjeva.pdf) for detecting fraudulent Skype users, and [comparing different classifiers](http://www.cse.ust.hk/nevinZhangGroup/readings/yi/Bradley_PR97.pdf) on a number of popular datasets\n",
    "\n",
    "### 12. Other Resources\n",
    "\n",
    "- scikit-learn documentation: [Model evaluation](http://scikit-learn.org/stable/modules/model_evaluation.html)\n",
    "- Guide: [Comparing model evaluation procedures and metrics](https://github.com/justmarkham/DAT8/blob/master/other/model_evaluation_comparison.md) by me\n",
    "- Video: [Counterfactual evaluation of machine learning models](https://www.youtube.com/watch?v=QWCSxAKR-h0) (45 minutes) about how Stripe evaluates its fraud detection model, including [slides](http://www.slideshare.net/MichaelManapat/counterfactual-evaluation-of-machine-learning-models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
